{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ctran Breadcrumb Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definitions\n",
    "\n",
    "**reading**: A **_reading_** is a unique entry from a c-tran breadcrumb data collection source (e.g. a bus pushing data). A **_reading_** is composed of multiple fields and is considered well-formed if all fields are present and all fields are of the correct datatype. Additionally, a **_reading_** is considered unique if it's well-formed and the set of it's field values are unique throughout the entirety of the data. In practice, each reading relates to each row in a database or dataframe.\n",
    "\n",
    "At the time of writing, a **_reading_** contains these fields with these datatypes:\n",
    "\n",
    "| Field name | EVENT_NO_TRIP | OPD_DATE | VEHICLE_ID | METERS  | ACT_TIME | GPS_LONGITUDE | GPS_LATITUDE |\n",
    "|------------|---------------|----------|------------|---------|----------|---------------|--------------|\n",
    "| Datatype   | integer       | date     | integer    | integer | integer  | float w/ precision 6 | float w/ precision 6|\n",
    "\n",
    "\n",
    "Example:\n",
    "\n",
    "| Field name | EVENT_NO_TRIP | OPD_DATE | VEHICLE_ID | METERS  | ACT_TIME | GPS_LONGITUDE | GPS_LATITUDE |\n",
    "|------------|---------------|----------|------------|---------|----------|---------------|--------------|\n",
    "| Values     | 152011646     | 24-FEB-20| 1776       | 77999   | 28558    | -122.579383   | 45.533608    |\n",
    "\n",
    "**vehicle**: A **_vehicle_** is any datasource sending valid readings over time. Additionally, it must have a unique `VEHICLE_ID` which is sent within each reading. \n",
    "\n",
    "**path**: A **_path_** is a line connecting two points in 2D-space by the shortest path (i.e. as the crow flies). A point is defined as an `x`-`y` coordinate pair and its units are inconsequential -- as long as they're the same for botht the `x` and `y` coordintate. In practice, a point looks like a longitude-latitude coordinate pair, or an x-y coordinate pair with a known origin (e.g. the bottom left corner of Clark County). It's also important to note that, for the purposes of this project, the surface of any geodetic system (e.g. a sphere or the earth) is considered 2D-space. That is, the **_path_** between two points on the earth would be \"curved\" as it travels across the surface of it and not \"through\" it.\n",
    "\n",
    "- route\n",
    "- day\n",
    "- iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Schema Definition\n",
    "\n",
    "For the purposes of this notebook the schema is based off of pandas however, there there is a schema that defines a table within a postgresql database which is also defined here. The only notable difference is the datatype of the `GPS_LATITUDE` and `GPS_LONGITUDE` fields.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Grab all tsv data from the `data` directory\n",
    "# ALL_DATA_FILES = glob(\"../data/**/*.csv\")\n",
    "ALL_DATA_FILES = glob(\"../data/**/bos_20200301620.csv\")\n",
    "\n",
    "def load_data():\n",
    "    ### Data columns are:\n",
    "    ### \"EVENT_NO_TRIP\"\t\"OPD_DATE\"\t\"VEHICLE_ID\"\t\"METERS\"\t\"ACT_TIME\"\t\"GPS_LONGITUDE\"\t\"GPS_LATITUDE\"\n",
    "\n",
    "    # Taken and modified from https://stackoverflow.com/a/21232849/4668680\n",
    "    return pd.concat(\n",
    "        [pd.read_csv(_file, parse_dates=[1]) for _file in ALL_DATA_FILES], ignore_index=True\n",
    "    )\n",
    "\n",
    "df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.13 s ± 85.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n1 df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unique_vehicle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a835c5ce4e09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mday_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"OPD_DATE\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mday\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0munique_vehicles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mday_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVEHICLE_ID\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mlookup_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mday\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0munique_vehicle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0munique_vehicle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munique_vehicles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'unique_vehicle' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "unique_days = df[\"OPD_DATE\"].unique()\n",
    "lookup_table = {day:{} for day in unique_days}\n",
    "\n",
    "# Get dataframes for each unique vehicle for each unique day\n",
    "for day in unique_days:\n",
    "    day_df = df.loc[df[\"OPD_DATE\"] == day]\n",
    "    unique_vehicles = day_df.VEHICLE_ID.unique()\n",
    "    lookup_table[day] = {unique_vehicle:None}\n",
    "    \n",
    "    for unique_vehicle in unique_vehicles:\n",
    "        vehicle_df = day_df.loc[day_df[\"VEHICLE_ID\"] == unique_vehicle]\n",
    "        lookup_table[day][unique_vehicle] = vehicle_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See: https://stackoverflow.com/a/48431023/4668680\n",
    "\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "\n",
    "def getDistanceFromLatLonInKm(lat1,lon1,lat2,lon2):\n",
    "    R = 6371 # Radius of the earth in km\n",
    "#     R = 3956\n",
    "    dLat = radians(lat2-lat1)\n",
    "    dLon = radians(lon2-lon1)\n",
    "    rLat1 = radians(lat1)\n",
    "    rLat2 = radians(lat2)\n",
    "    a = sin(dLat/2) * sin(dLat/2) + cos(rLat1) * cos(rLat2) * sin(dLon/2) * sin(dLon/2) \n",
    "    c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "    d = R * c # Distance in km\n",
    "    return d\n",
    "\n",
    "def calc_velocity(dist_km, time_start, time_end):\n",
    "    \"\"\"Return 0 if time_start == time_end, avoid dividing by 0\"\"\"\n",
    "    return dist_km / ((time_end - time_start).seconds / 3600) if time_end > time_start else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1776",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-90e6f61b422d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtmp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2020-03-16T00:00:00.000000000'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1776\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Convert OPD_DATE + ACT_TIME to timestamp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPD_DATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1776"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "tmp_df = lookup_table[np.datetime64('2020-03-16T00:00:00.000000000')][1776]\n",
    "\n",
    "# Convert OPD_DATE + ACT_TIME to timestamp\n",
    "dates = pd.to_datetime(df.OPD_DATE, cache=True)\n",
    "times = pd.to_timedelta(df.ACT_TIME, unit=\"seconds\")\n",
    "tmp_df[\"timestamp\"] = dates + times\n",
    "\n",
    "\n",
    "# First sort by ID and timestamp:\n",
    "tmp_df = tmp_df.sort_values(by=['timestamp'])\n",
    "# print(tmp_df)\n",
    "\n",
    "# Group the sorted dataframe by ID, and grab the initial value for lat, lon, and time.\n",
    "tmp_df['lat0'] = tmp_df[\"GPS_LATITUDE\"][0]\n",
    "tmp_df['lon0'] = tmp_df[\"GPS_LONGITUDE\"][0]\n",
    "tmp_df[\"t0\"] = tmp_df[\"timestamp\"][0]\n",
    "\n",
    "tmp_df['dist_km'] = tmp_df.apply(\n",
    "    lambda row: getDistanceFromLatLonInKm(\n",
    "        lat1=row['GPS_LATITUDE'],\n",
    "        lon1=row['GPS_LONGITUDE'],\n",
    "        lat2=row['lat0'],\n",
    "        lon2=row['lon0']\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "tmp_df['velocity_kmh'] = tmp_df.apply(\n",
    "    lambda row: calc_velocity(\n",
    "        dist_km=row['dist_km'],\n",
    "        time_start=row['t0'],\n",
    "        time_end=row['timestamp']\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "print(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df)\n",
    "UNIQUE_TRIP_NOS = df[\"EVENT_NO_TRIP\"].unique()\n",
    "UNIQUE_DATES = df[\"OPD_DATE\"].unique()\n",
    "UNIQUE_VEHICLES = df[\"VEHICLE_ID\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which dates are tracked, are these weekdays or weekend days?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "\n",
    "# Test all dates are weekdays\n",
    "unique_days = pd.Series(UNIQUE_DATES)\n",
    "# print(unique_days.dt.day_name())\n",
    "\n",
    "is_all_weekdays = pd.Series([(day != \"Saturday\" and day != \"Sunday\") for day in unique_days]).all()\n",
    "print(is_all_weekdays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "min   2020-02-24\n",
       "max   2020-03-20\n",
       "Name: OPD_DATE, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.OPD_DATE.agg([\"min\", \"max\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Are the same vehicles tracked each day or does it change from day to day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "date_group = df.groupby(\"OPD_DATE\")\n",
    "\n",
    "df2 = date_group.apply(lambda x: len(x[\"VEHICLE_ID\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPD_DATE\n",
       "2020-02-24    100\n",
       "2020-02-25     95\n",
       "2020-02-26    100\n",
       "2020-02-27     97\n",
       "2020-02-28     99\n",
       "2020-03-02    100\n",
       "2020-03-03     97\n",
       "2020-03-04     97\n",
       "2020-03-05     99\n",
       "2020-03-06     98\n",
       "2020-03-09    103\n",
       "2020-03-10    102\n",
       "2020-03-11    100\n",
       "2020-03-12    102\n",
       "2020-03-13    102\n",
       "2020-03-16    102\n",
       "2020-03-17    104\n",
       "2020-03-18    104\n",
       "2020-03-19    101\n",
       "2020-03-20     99\n",
       "dtype: int64"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The ACT_TIME columns seems to represent the time at which the event occurred. what are its units?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "min     4.181111\n",
       "max    25.683611\n",
       "Name: ACT_TIME, dtype: float64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It's units appear to be seconds offset from midnight; this is the min/max time in hours\n",
    "df.ACT_TIME.agg([\"min\", \"max\"]).div(60 * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relating to last: Can you convert this to datetime format?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         2020-03-09 05:02:53\n",
      "1         2020-03-09 05:02:58\n",
      "2         2020-03-09 05:03:03\n",
      "3         2020-03-09 05:03:08\n",
      "4         2020-03-09 05:03:13\n",
      "                  ...        \n",
      "8623465   2020-03-20 18:35:05\n",
      "8623466   2020-03-20 18:35:10\n",
      "8623467   2020-03-20 18:35:15\n",
      "8623468   2020-03-20 18:35:20\n",
      "8623469   2020-03-20 18:35:25\n",
      "Name: ACT_DTG, Length: 8623470, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# TODO: This would be more useful related to vehicle IDs\n",
    "# TODO: This doesn't appear to maintain order\n",
    "df[\"ACT_DTG\"] = df.OPD_DATE + pd.to_timedelta(df.ACT_TIME, unit=\"s\")\n",
    "print(df.ACT_DTG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Are the events spaced evenly in time or are the events more frequent at specific times of day (for a given vehicle)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the delta from reading to reading; is it always 5 seconds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([   1776,    1776,    1776,    1776,    1776,    1776,    1776,\n",
      "               1776,    1776,    1776,\n",
      "            ...\n",
      "            1298380, 1298380, 1298380, 1298380, 1298380, 1298380, 1298380,\n",
      "            1298380, 1298380, 1298380],\n",
      "           dtype='int64', name='VEHICLE_ID', length=8623470)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# What is the METERS field?\n",
    "index = pd.Index(df.VEHICLE_ID)\n",
    "# Meters with vehicle id index\n",
    "meters_series = pd.Series(df.METERS, index=index)\n",
    "\n",
    "monotonic_meters = pd.Series(meters_series.groupby(level=0).is_monotonic_increasing)\n",
    "print(monotonic_meters.all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which route has the largest birds-eye distance? The smallest distance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           GPS_LATITUDE            GPS_LONGITUDE            \n",
      "                    min        max           min         max\n",
      "VEHICLE_ID                                                  \n",
      "1002                NaN        NaN           NaN         NaN\n",
      "1776          45.494440  45.736335   -122.689590 -122.503760\n",
      "2215          45.494420  45.721972   -122.689602 -122.503748\n",
      "2218          45.494393  45.736378   -122.689605 -122.503738\n",
      "2220          45.494432  45.780962   -122.702240 -122.503760\n",
      "...                 ...        ...           ...         ...\n",
      "1254260       45.494432  45.722098   -122.702247 -122.503723\n",
      "1254280       45.494422  45.721990   -122.689585 -122.503735\n",
      "1254282       45.494375  45.724643   -122.689592 -122.503718\n",
      "1254300       45.494418  45.723113   -122.702272 -122.503745\n",
      "1298380       45.505045  45.780973   -122.686907 -122.475703\n",
      "\n",
      "[117 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "index = pd.MultiIndex.from_frame(df[[\"OPD_DATE\", \"VEHICLE_ID\"]])\n",
    "\n",
    "# Index by unique vehicles per day\n",
    "wanted_columns = [\"GPS_LATITUDE\", \"GPS_LONGITUDE\"]\n",
    "lat_long_df = pd.DataFrame(\n",
    "    df[wanted_columns].to_numpy(), columns=wanted_columns, index=index\n",
    ")\n",
    "\n",
    "# TODO: Why does vehicle id 1002 have NaN\n",
    "# Intermediate step to min/max lat/long of each vehicle (across all days)\n",
    "all_v_min_max = lat_long_df.groupby(\"VEHICLE_ID\").agg([\"min\", \"max\"]).reindex(axis=1)\n",
    "print(all_v_min_max)\n",
    "\n",
    "# idx = pd.IndexSlice\n",
    "# lat_mins = all_v_min_max.loc[:,[\"GPS_LATITUDE\"]]\n",
    "# maxs = all_v_min_max.loc[:,idx[:,\"max\"]]\n",
    "# print(lat_mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use datetimes instead of strings for date comparisons\n",
    "for bus_id in UNIQUE_VEHICLES:\n",
    "    assert df[\n",
    "        (df.OPD_DATE == \"20-MAR-20\") & (df.VEHICLE_ID == bus_id)\n",
    "    ].METERS.is_monotonic, f\"{bus_id} METERS is not monotonically increasing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    POLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\n",
       "1    POLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\n",
       "2    POLYGON ((2.00000 0.00000, 3.00000 0.00000, 3....\n",
       "dtype: geometry"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import geopandas\n",
    "from shapely.geometry import Polygon\n",
    "p1 = Polygon([(0, 0), (1, 0), (1, 1)])\n",
    "p2 = Polygon([(0, 0), (1, 0), (1, 1), (0, 1)])\n",
    "p3 = Polygon([(2, 0), (3, 0), (3, 1), (2, 1)])\n",
    "g = geopandas.GeoSeries([p1, p2, p3])\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
